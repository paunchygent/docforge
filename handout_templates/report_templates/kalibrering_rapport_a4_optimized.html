<!DOCTYPE html>
<html lang="sv">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="handout:pdf:inject_supplementary_css" content="false">
    <title>Kalibrering Rapport - Uppdaterad med aktuell data</title>
    <link rel="stylesheet" href="kalibrering_rapport_style.css">
</head>
<body>
    <div class="container">
        <h1>Vad är det egentligen som pågår, Olof?</h1>

        <p>Ok! Nedan följer ett försök att sammanfatta vad det egentligen var ni gjorde på det där första (skälvande?) ämneslagsmötet i augusti. För er som redan har förträngt den första arbetsveckans vedermödor: ni bedömde elevuppsatser skrivna som svar på uppsatsdelen från NP i kursen Engelska 5 (från VT 2016). Målet var att ta fram <strong>ankaruppsatser</strong> – elevtexter med ett så rättvist och stabilt betyg som möjligt – som kan användas för att kalibrera min <em>comparative judgement</em>-modell.</p>

        <p>Ankaruppsatserna fungerar som fasta referenspunkter när systemet jämför och rangordnar nya elevuppsatser. Processen går till så att "vanliga" uppsatser (utan känt betyg) jämförs mot varandra och med de inblandade ankaruppsatserna vars betyg redan är fastställda. När alla uppsatser har jämförts med varandra kan vi ranka dem genom att analysera vilka uppsatser som vann respektive förlorade mest matcher och hur svåra eller lätta motståndarna i dessa matcher var. Eftersom ankaruppsatsernas betyg är kända kan systemet sedan beräkna det mest sannolika betyget för alla övriga uppsatser baserat på var de hamnar relativt ankarna i rankningen.</p>

        <div class="highlight">
            <h3>Viktigt: Bifogade bedömningsanvisningar</h3>
            <p>Tillsammans med rapporten har jag bifogat <strong>bedömningsanvisningarna för det nationella provet i Engelska 5 VT 2017</strong>. Det är viktigt att samtliga läser in sig på de kritiska delarna innan onsdagens konferens:</p>
            <ul>
                <li><strong>De inledande bedömningsanvisningarna (se sidan 7)</strong> </li>
                <li><strong>De bedömda exempeluppsatserna (se sidan 8-33)</strong> – Fokusera främst uppsatserna snarare än bedömningarna, eftersom vi kommer att göra holistiska jämförelser mellan dem och uppsatserna vi betygsatte i augusti</li>
            </ul>
            <p>Detta är nödvändigt för att:</p>
            <ul>
                <li>Ni ska få en gemensam bild av vad som krävs på varje betygsnivå redan innan konferensen</li>
                <li>Vi ska kunna kalibrera oss mot bedömningsinstruktionerna</li>
                <li>De kalibrerande diskussionerna efter comparative judgement/komparativ bedömning ska bli mer produktiva och fokuserade</li>
            </ul>
        </div>

        <div class="highlight" style="background-color: #e8f4f8; border-left: 4px solid #2196F3;">
            <h2>Varför comparative judgement/komparativ bedömning?</h2>

            <h3>Problemet med absoluta bedömningar</h3>
            <p>I augusti genomförde ni <strong>absoluta bedömningar</strong> – det vill säga, varje lärare tittade på varje uppsats och satte ett betyg utifrån sin egen tolkning av betygskriterierna. Som resultaten i denna rapport visar leder detta till flera problem:</p>
            <ul>
                <li><strong>Stor spridning:</strong> För vissa uppsatser skiljer det upp till 5 betygssteg mellan bedömarna</li>
                <li><strong>Systematiska skillnader:</strong> Vissa lärare är konsekvent strängare eller mer generösa än andra</li>
                <li><strong>Låg samstämmighet:</strong> Krippendorffs alpha på 0.56 ligger under gränsen för tillförlitliga slutsatser</li>
                <li><strong>Kognitiv belastning:</strong> Att hålla hela betygsskalan och alla kriterier i huvudet samtidigt som man bedömer är en tung arbetsuppgift</li>
            </ul>

            <h3>Fördelarna med komparativ bedömning</h3>
            <p><strong>Komparativ bedömning</strong> fungerar på ett helt annat sätt. Istället för att sätta ett absolut betyg på varje uppsats, jämför ni helt enkelt två uppsatser åt gången och avgör vilken som är bättre. Detta är en mycket enklare och mer tillförlitlig bedömningsuppgift för oss människor. Forskning visar att komparativa bedömningar ger:</p>
            <ul>
                <li><strong>Högre tillförlitlighet:</strong> Samstämmigheten mellan bedömare ökar markant jämfört med absoluta bedömningar</li>
                <li><strong>Mindre snedvridning:</strong> Systematiska skillnader i stränghet får mindre genomslag när man bara jämför två uppsatser</li>
                <li><strong>Lägre kognitiv belastning:</strong> Att svara på "vilken är bättre?" är mycket lättare än "vilket exakt betyg ska denna få?"</li>
                <li><strong>Mer naturligt:</strong> Vi människor är bättre på att göra jämförelser än att sätta absoluta betyg</li>
            </ul>

            <h3>Tänkt uppläggning</h3>
            <p>På onsdagens konferens kommer ni att jämföra elevuppsatserna parvis mot varandra och mot exempeluppsatserna från bedömningsanvisningarna. Genom att analysera vilka uppsatser som "vinner" sina matcher kan vi sedan rangordna dem och låta ankaruppsatserna koppla denna rankning till faktiska betyg. Resultatet blir en mycket mer tillförlitlig bedömning än de absoluta betygen från augusti.</p>
        </div>

        <h2>Metod för att beräkna konsensusbetyg</h2>

        <p>För att göra bedömningarna jämförbara används en statistisk modell som tar hänsyn till att olika lärare kan vara mer eller mindre strikta. I stället för att behandla betyg som exakta tal betraktar modellen betygsstegen (F, F+, E, E+, D–, D+, C–, C+, B, A) som en <em>ordning</em><sup>[1]</sup>. Modellen kallas en <strong>kumulativ logistisk modell</strong> och fungerar i flera steg:</p>

        <ol>
            <li>Varje uppsats antas ha en underliggande kvalitetsnivå som vi vill uppskatta genom att kombinera alla bedömningar.</li>
            <li>Varje bedömare antas ha en personlig stränghet. En sträng lärare sänker betygen jämfört med genomsnittet, en generös lärare höjer dem.</li>
            <li>Modellen beräknar var gränserna mellan betygsstegen bör ligga baserat på era faktiska bedömningar. Den upptäcker till exempel att steget från C- till C+ är det största i hela skalan<sup>[2]</sup>.</li>
            <li>Genom att väga samman alla bedömningar och justera för varje bedömares stränghetsprofil får vi ett <strong>konsensusbetyg</strong> för varje uppsats.</li>
        </ol>

        <p>På så sätt får varje uppsats ett betyg som representerar dess mest sannolika kvalitetsnivå baserat på alla bedömningar, efter att ha rensat bort effekten av individuella bedömares stränghet. Man kan se det som det betyg uppsatsen troligen skulle få av en "neutral" bedömare – eller som panelens samlade bedömning efter justering för era olika bedömarprofiler. Dessa justerade betyg används sedan för att rangordna uppsatserna och välja ut ankaruppsatserna för AI-systemet.</p>

        <div class="footnote">
            <p><sup>[1]</sup> <strong>Ordning:</strong> Modellen bryr sig bara om rangordningen mellan betygen (F är lägre än E, som är lägre än D, och så vidare). Den antar inte att avståndet mellan F och E är lika stort som mellan D och C – avstånden får vara olika stora, vilket våra resultat också visar.</p>
            <p><sup>[2]</sup> <strong>Betygsgränserna anpassas efter data:</strong> Istället för att anta att alla betygssteg är lika stora låter modellen era bedömningar avgöra hur stora kvalitetshoppen mellan betygen faktiskt är. Via vårt förfarande kan vi skönja ett intressant mönster – steget från C- till C+ är det största i hela skalan, vilket jag och säkert många med mig känner igen från vår undervisning.</p>
        </div>

        <h2>Resultat: Uppsatsernas rangordning</h2>

        <div class="figure">
            <img src="figur1_uppsatskvalitet.png" alt="Uppsatskvalitet">
            <div class="figure-caption">
                <strong>Figur 1: Uppsatsernas beräknade kvalitet efter justering för bedömarstränghet.</strong> Staplarna visar den underliggande kvaliteten (ability score) sorterat från lägst till högst. Blå staplar indikerar uppsatser över genomsnittet (5.5), lila staplar under. Konsensusbetyget visas i parentes efter varje uppsats-ID. JA24 ligger klart högst med värde 8.50 (B), följt av II24 med 7.83 (B). JP24 har lägst värde med 3.43 (E+).
            </div>
        </div>

        <h3>Uppsatser med högst och lägst kvalitetsvärden</h3>
        <table>
            <thead>
                <tr>
                    <th>Uppsats-ID</th>
                    <th>Konsensusbetyg</th>
                    <th>Underliggande kvalitet<sup>[3]</sup></th>
                    <th>Konfidens<sup>[4]</sup></th>
                </tr>
            </thead>
            <tbody>
                <tr class="table-header-success">
                    <td colspan="4"><strong>Högst rankade</strong></td>
                </tr>
                <tr>
                    <td>JA24</td>
                    <td><strong>B</strong></td>
                    <td>8.50</td>
                    <td>0.39</td>
                </tr>
                <tr>
                    <td>II24</td>
                    <td><strong>B</strong></td>
                    <td>7.83</td>
                    <td>0.37</td>
                </tr>
                <tr>
                    <td>ES24</td>
                    <td><strong>C+</strong></td>
                    <td>7.43</td>
                    <td>0.31</td>
                </tr>
                <tr class="table-header-warning">
                    <td colspan="4"><strong>Lägst rankade</strong></td>
                </tr>
                <tr>
                    <td>LW24</td>
                    <td><strong>D+</strong></td>
                    <td>4.65</td>
                    <td>0.23</td>
                </tr>
                <tr>
                    <td>JF24</td>
                    <td><strong>D+</strong></td>
                    <td>4.61</td>
                    <td>0.29</td>
                </tr>
                <tr>
                    <td>JP24</td>
                    <td><strong>E+</strong></td>
                    <td>3.43</td>
                    <td>0.12</td>
                </tr></tbody>
        </table>

        <div class="footnote">
            <p><sup>[3]</sup> <strong>Underliggande kvalitet (ability score):</strong> Ett mått på uppsatsens kvalitetsnivå där genomsnittet ligger kring 5.5. JA24:s värde 8.50 betyder att uppsatsen ligger mycket högt över genomsnittet, medan JP24:s värde 3.43 ligger betydligt under.</p>
            <p><sup>[4]</sup> <strong>Konfidens:</strong> Visar hur säker modellen är på konsensusbetyget. Högre värde indikerar större säkerhet. Värden runt 0.30 anses generellt inte som tillförlitliga och beror på att vi saknar uppsatser vid samtliga trösklar, för att få ett mer rättvisande värde på tillförlitligheten kan vi slå ihop exvis D- och D+, vilket gör att tillförlitligheten hamnar på >0.6 för de flesta konsensusbetyg, vilket är acceptabelt.</p>
        </div>

        <h2>Resultat: Bedömarnas stränghet</h2>

        <p>Analysen visar att ni bedömer olika strängt – vilket är helt normalt, särskilt före kalibrering! Det viktiga är att vi tar hänsyn till detta i modellen.</p>

        <div class="figure">
            <img src="figur2_bedömarstränghet.png" alt="Bedömarstränghet">
            <div class="figure-caption">
                <strong>Figur 2: Systematiska skillnader i bedömarstränghet.</strong> Värdet 0 representerar genomsnittlig stränghet. <strong>Negativa värden (röda staplar) indikerar stränga bedömare</strong> som tenderar att ge lägre betyg än genomsnittet. <strong>Positiva värden (gröna staplar) visar generösa bedömare</strong> som ger högre betyg. Antalet bedömda uppsatser visas i parentes. Bedömare med färre bedömningar visas med lägre transparens.
            </div>
        </div>

        <table>
            <thead>
                <tr>
                    <th>Bedömar-ID</th>
                    <th>Stränghet</th>
                    <th>Antal bedömda</th>
                    <th>Tolkning</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>B13</td>
                    <td>-0.74</td>
                    <td>6</td>
                    <td>Sträng</td>
                </tr>
                <tr>
                    <td>B14</td>
                    <td>-0.56</td>
                    <td>2</td>
                    <td>Sträng*</td>
                </tr>
                <tr>
                    <td>B11</td>
                    <td>-0.39</td>
                    <td>4</td>
                    <td>Något sträng</td>
                </tr>
                <tr>
                    <td>B12</td>
                    <td>-0.29</td>
                    <td>5</td>
                    <td>Något sträng</td>
                </tr>
                <tr>
                    <td>B08</td>
                    <td>-0.16</td>
                    <td>5</td>
                    <td>Något sträng</td>
                </tr>
                <tr>
                    <td>B07</td>
                    <td>-0.08</td>
                    <td>5</td>
                    <td>Neutral</td>
                </tr>
                <tr>
                    <td>B10</td>
                    <td>-0.04</td>
                    <td>4</td>
                    <td>Neutral</td>
                </tr>
                <tr>
                    <td>B09</td>
                    <td>0.05</td>
                    <td>4</td>
                    <td>Neutral</td>
                </tr>
                <tr>
                    <td>B02</td>
                    <td>0.27</td>
                    <td>5</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B03</td>
                    <td>0.30</td>
                    <td>5</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B06</td>
                    <td>0.31</td>
                    <td>3</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B01</td>
                    <td>0.40</td>
                    <td>6</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B05</td>
                    <td>0.49</td>
                    <td>3</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B04</td>
                    <td>0.56</td>
                    <td>3</td>
                    <td>Generös</td>
                </tr></tbody>
        </table>
        <p><em>*B14 har endast bedömt 2 uppsatser vilket gör värdet mycket osäkert</em></p>

        <h2>Avstånden mellan betygsstegen</h2>

        <p>Modellen visar att betygsstegen inte är jämnstora. Vissa övergångar kräver stora kvalitetshopp medan andra är små – en observation som stämmer väl med många lärares erfarenhet - och med grundtanken bakom betygsskalor, som antar att betyg är normalfördelade.</p>

        <div class="figure">
            <img src="figur3_betygströsklar.png" alt="Betygströsklar">
            <div class="figure-caption">
                <strong>Figur 3: Hur stora är stegen mellan betygen?</strong> Övre panelen visar betygsgränserna som färgzoner. Varje färg representerar ett betygsområde från F (mörkröd) till A (mörkgrön). Nedre panelen visar storleken på stegen mellan betygsnivåerna. Gröna staplar = små steg, orange = medelstora, röda = stora steg. De största hoppen är från D+ till C- och från C- till C+. För att ta sig över C-gränsen måste eleverna kraftigt förbättra sin skrivförmåga – något som stämmer väl med många lärares erfarenhet att just denna gräns är särskilt svår att passera.
            </div>
        </div>

        <div class="highlight">
            <h3>Praktisk betydelse</h3>
            <p>Analysen av faktiska avstånd mellan betygsnivåer visar att:</p>
            <ul>
                <li>Steget från D+ till C- är det minsta: 0.96 enheter</li>
                <li>Steget från C- till C+ är betydande: 1.26 enheter</li>
                <li>Steget från C+ till B är medelstort: 1.10 enheter</li>
            </ul>
            <p>OBS: Endast en uppsats fick E+ (JP24) samtidigt som ingen uppsats fick betyget D-, vilket gör det svårt att dra säkra slutsatser om dessa betygssteg.</p>
        </div>

        <h2>Bedömarsamstämmighet</h2>

        <p>Analys av hur väl ni överensstämmer i era bedömningar.</p>

        <div class="figure">
            <img src="figur4_bedömarspridning.png" alt="Bedömarspridning">
            <div class="figure-caption">
                <strong>Figur 4: Bedömarspridning per uppsats.</strong> Vänstra panelen visar spridningen i bedömningar för varje uppsats, sorterad från högst till lägst. Gröna staplar = god samstämmighet (≤2 betygssteg), orange = måttlig oenighet (3 steg), röda = stor oenighet (≥4 steg). JP24 sticker ut med 5 betygssteg i spridning – här är bedömarna verkligen oense. LW24 har också stor spridning med 4 steg. Högra panelen visar fördelningen över alla uppsatser. Cirka 50% har god samstämmighet medan 33% har måttlig oenighet. Detta är faktiskt helt normalt för uppsatsbedömning – internationell forskning visar liknande mönster.
            </div>
        </div>

        <h3>Sammanfattande mått</h3>
        <ul>
            <li><strong>Krippendorffs alpha:</strong> 0.56 (måttlig samstämmighet)</li>
            <li><strong>Medianspridning:</strong> 2 betygssteg</li>
            <li><strong>Uppsatser med stor oenighet (≥3 steg):</strong> 50%</li>
            <li><strong>Uppsatser med mycket stor oenighet (≥4 steg):</strong> 16%</li>
        </ul>

        <p>Ett alpha-värde på 0.56 ligger under den gräns (0.667) som Krippendorff rekommenderar för att dra säkra slutsatser. Det är dock viktigt att komma ihåg att vi inte genomfört någon gemensam kalibreringsträning innan bedömningen – ni fick uppsatserna och bedömde dem individuellt utifrån era egna tolkningar av betygskriterierna. Med tanke på detta är 0.56 faktiskt inte så illa. Efter kalibreringsträffar brukar samstämmigheten öka markant.</p>

        <h2>Plan</h2>

        <div class="recommendation">
            <h3>Förberedelse inför konferensen</h3>
            <p><strong>Viktigt:</strong> Läs igenom de bifogade bedömningsanvisningarna noggrant innan onsdagens konferens.</p>
            
            <h3>Onsdagens konferens 29/10</h3>
            <p>På onsdagens ämneskonferens kommer jag att presentera ett schema för komparativa bedömningar där vi:</p>
            <ul>
                <li>Använder de bifogade bedömningsanvisningarna tillsammans med exempeluppsatserna</li>
                <li>Jämför elevuppsatserna med varandra genom komparativ bedömning</li>
                <li>Diskuterar spridningen i bedömningarna och hur vi värderar uppsatsernas kvalitetsaspekter</li>
                <li>Kalibrerar vår gemensamma förståelse av betygsnivåerna</li>
            </ul>
        </div>

        <h2>Tidslinje</h2>

        <ol>
            <li><strong>Vecka 44:</strong> Onsdagens ämneskonferens - presentation av komparativt bedömningsschema</li>
            <li><strong>Vecka 47-02:</strong> Genomförande av komparativa bedömningar och justeringar av modellen</li>
            <li><strong>December/januari:</strong> Pilottest med elevernas mid-terms</li>
            <li><strong>April/maj:</strong> Skarpt läge efter NP, Del C: Writing</li>
        </ol>

        <h2>Avslutande kommentarer</h2>

        <p>Analysen visar att ni bedömer olika – vissa är konsekvent strängare (negativa värden) medan andra är mer generösa (positiva värden) i sin bedömning. För vissa uppsatser skiljer det upp till fem betygssteg mellan er. Det är inget konstigt utan helt normalt! Poängen med den bayesianska modellen är att den kan räkna ut ett konsensusbetyg för varje uppsats, justerat för era individuella bedömarprofiler. De uppsatser som får stabila konsensusbetyg (hög konfidens) blir våra ankaruppsatser.</p>

        <p>Nästa steg blir att samla in de kompletterande bedömningarna under onsdagens konferens. Därefter kör vi om analysen och får förhoppningsvis mer tillförlitliga siffror för alla bedömare. I pilottestet får vi se om ankaruppsatserna verkligen fungerar som stabila referenspunkter när AI-systemet ska rangordna och betygsätta elevuppsatserna.</p>

        <p class="closing"><em>Tack och hej, leverpastej,</em></p>
        <p><em>Olof</em></p>

        <hr>
        <p class="footer-note">
            <em>En oerhört parentetisk fotnot: Analysen baseras på en ordinal kumulativ logit-modell som skattar underliggande uppsatskvalitet (θ), bedömarstränghet (ρ) och betygsgränser (τ) samtidigt. Modellen använder nollsummerestriktion (Σρ = 0) för identifiering och monotont ökande betygsgränser. Inget antagande om lika avstånd mellan betygsstegen görs – stegen tillåts vara olika stora, vilket data bekräftar (särskilt de stora hoppen vid C-gränserna). Genomförd i Python/PyMC med 2000 MCMC-dragningar över 4 kedjor.</em>
        </p>
    </div>
</body>
</html>
