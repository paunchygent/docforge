<!DOCTYPE html>
<html lang="sv">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="handout:pdf:inject_supplementary_css" content="false">
    <title>Kalibrering Rapport - Uppdaterad med aktuell data</title>
    <link rel="stylesheet" href="report_template.css">
</head>
<body>
    <div class="container">
        <h1>Va fan får jag för pengarna, Olof?</h1>

        <p>Ok! Nedan följer ett försök att sammanfatta vad det egentligen var ni gjorde på det där första (skälvande?) ämneslagsmötet i augusti. För er som redan har förträngt den första arbetsveckans vedermödor: ni bedömde elevuppsatser skrivna som svar på uppsatsdelen från NP i kursen Engelska 5 (från VT 2016). Målet var att ta fram <strong>ankaruppsatser</strong> – elevtexter med ett så rättvist och stabilt betyg som möjligt – som kan användas för att kalibrera min <em>comparative judgement</em>-modell.</p>

        <p>Ankaruppsatserna fungerar som fasta referenspunkter när systemet jämför och rangordnar nya elevuppsatser. Processen går till så att "vanliga" uppsatser (utan känt betyg) jämförs mot varandra och med de inblandade ankaruppsatserna vars betyg redan är fastställda. När alla uppsatser har jämförts med varandra kan vi ranka dem genom att analysera vilka uppsatser som vann respektive förlorade mest matcher och hur svåra eller lätta motståndarna i dessa matcher var. Eftersom ankaruppsatsernas betyg är kända kan systemet sedan beräkna det mest sannolika betyget för alla övriga uppsatser baserat på var de hamnar relativt ankarna i rankningen.</p>

        <h2>Metod för att beräkna konsensusbetyg</h2>

        <p>För att göra bedömningarna jämförbara används en statistisk modell som tar hänsyn till att olika lärare kan vara mer eller mindre strikta. I stället för att behandla betyg som exakta tal betraktar modellen betygsstegen (F, F+, E, E+, D–, D+, C–, C+, B, A) som en <em>ordning</em><sup>[1]</sup>. Modellen kallas en <strong>kumulativ logistisk modell</strong> och fungerar i flera steg:</p>

        <ol>
            <li>Varje uppsats antas ha en underliggande kvalitetsnivå som vi vill uppskatta genom att kombinera alla bedömningar.</li>
            <li>Varje bedömare antas ha en personlig stränghet. En sträng lärare sänker betygen jämfört med genomsnittet, en generös lärare höjer dem.</li>
            <li>Modellen beräknar var gränserna mellan betygsstegen bör ligga baserat på era faktiska bedömningar. Den upptäcker till exempel att steget från C- till C+ är det största i hela skalan<sup>[2]</sup>.</li>
            <li>Genom att väga samman alla bedömningar och justera för varje bedömares stränghetsprofil får vi ett <strong>konsensusbetyg</strong> för varje uppsats.</li>
        </ol>

        <p>På så sätt får varje uppsats ett betyg som representerar dess mest sannolika kvalitetsnivå baserat på alla bedömningar, efter att ha rensat bort effekten av individuella bedömares stränghet. Man kan se det som det betyg uppsatsen troligen skulle få av en "neutral" bedömare – eller som panelens samlade bedömning efter justering för era olika bedömarprofiler. Dessa justerade betyg används sedan för att rangordna uppsatserna och välja ut ankaruppsatserna för AI-systemet.</p>

        <div class="footnote">
            <p><sup>[1]</sup> <strong>Ordning:</strong> Modellen bryr sig bara om rangordningen mellan betygen (F är lägre än E, som är lägre än D, och så vidare). Den antar inte att avståndet mellan F och E är lika stort som mellan D och C – avstånden får vara olika stora, vilket våra resultat också visar.</p>
            <p><sup>[2]</sup> <strong>Betygsgränserna anpassas efter data:</strong> Istället för att anta att alla betygssteg är lika stora låter modellen era bedömningar avgöra hur stora kvalitetshoppen mellan betygen faktiskt är. Via vårt förfarande kan vi skönja ett intressant mönster – steget från C- till C+ är det största i hela skalan, vilket jag och säkert många med mig känner igen från vår undervisning.</p>
        </div>

        <h2>Resultat: Uppsatsernas rangordning</h2>

        <div class="figure">
            <img src="figur1_uppsatskvalitet.png" alt="Uppsatskvalitet">
            <div class="figure-caption">
                <strong>Figur 1: Uppsatsernas beräknade kvalitet efter justering för bedömarstränghet.</strong> Staplarna visar den underliggande kvaliteten (ability score) sorterat från lägst till högst. Blå staplar indikerar uppsatser över genomsnittet (5.5), lila staplar under. Konsensusbetyget visas i parentes efter varje uppsats-ID. JA24 ligger klart högst med värde 8.50 (B), följt av II24 med 7.83 (B). JP24 har lägst värde med 3.43 (E+).
            </div>
        </div>

        <h3>Uppsatser med högst och lägst kvalitetsvärden</h3>
        <table>
            <thead>
                <tr>
                    <th>Uppsats-ID</th>
                    <th>Konsensusbetyg</th>
                    <th>Underliggande kvalitet<sup>[3]</sup></th>
                    <th>Konfidens<sup>[4]</sup></th>
                </tr>
            </thead>
            <tbody>
                <tr style="background-color: #E8F5E9;">
                    <td colspan="4"><strong>Högst rankade</strong></td>
                </tr>
                <tr>
                    <td>JA24</td>
                    <td><strong>B</strong></td>
                    <td>8.50</td>
                    <td>0.39</td>
                </tr>
                <tr>
                    <td>II24</td>
                    <td><strong>B</strong></td>
                    <td>7.83</td>
                    <td>0.37</td>
                </tr>
                <tr>
                    <td>ES24</td>
                    <td><strong>C+</strong></td>
                    <td>7.43</td>
                    <td>0.31</td>
                </tr>
                <tr style="background-color: #FFEBEE;">
                    <td colspan="4"><strong>Lägst rankade</strong></td>
                </tr>
                <tr>
                    <td>LW24</td>
                    <td><strong>D+</strong></td>
                    <td>4.65</td>
                    <td>0.23</td>
                </tr>
                <tr>
                    <td>JF24</td>
                    <td><strong>D+</strong></td>
                    <td>4.61</td>
                    <td>0.29</td>
                </tr>
                <tr>
                    <td>JP24</td>
                    <td><strong>E+</strong></td>
                    <td>3.43</td>
                    <td>0.12</td>
                </tr></tbody>
        </table>

        <div class="footnote">
            <p><sup>[3]</sup> <strong>Underliggande kvalitet (ability score):</strong> Ett mått på uppsatsens kvalitetsnivå där genomsnittet ligger kring 5.5. JA24:s värde 8.50 betyder att uppsatsen ligger mycket högt över genomsnittet, medan JP24:s värde 3.43 ligger betydligt under.</p>
            <p><sup>[4]</sup> <strong>Konfidens:</strong> Visar hur säker modellen är på konsensusbetyget. Högre värde indikerar större säkerhet. Värden runt 0.30 anses generellt inte som tillförlitliga och beror på att vi saknar uppsatser vid samtliga trösklar, för att få ett mer rättvisande värde på tillförlitligheten kan vi slå ihop exvis D- och D+, vilket gör att tillförlitligheten hamnar på >0.6 för de flesta konsensusbetyg, vilket är acceptabelt.</p>
        </div>

        <h2>Resultat: Bedömarnas stränghet</h2>

        <p>Analysen visar att ni bedömer olika strängt – vilket är helt normalt! Det viktiga är att vi kan ta hänsyn till detta i modellen.</p>

        <div class="figure">
            <img src="figur2_bedömarstränghet.png" alt="Bedömarstränghet">
            <div class="figure-caption">
                <strong>Figur 2: Systematiska skillnader i bedömarstränghet.</strong> Värdet 0 representerar genomsnittlig stränghet. <strong>Negativa värden (röda staplar) indikerar stränga bedömare</strong> som tenderar att ge lägre betyg än genomsnittet. <strong>Positiva värden (gröna staplar) visar generösa bedömare</strong> som ger högre betyg. Antalet bedömda uppsatser visas i parentes. B13 är strängast med -0.74 medan B04 är generösast med +0.56. Observera att B14 (markerad med ⚠) endast har bedömt 2 uppsatser vilket gör värdet extremt osäkert. Bedömare med färre bedömningar visas med lägre transparens.
            </div>
        </div>

        <table>
            <thead>
                <tr>
                    <th>Bedömar-ID</th>
                    <th>Stränghet</th>
                    <th>Antal bedömda</th>
                    <th>Tolkning</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>B13</td>
                    <td>-0.74</td>
                    <td>6</td>
                    <td>Sträng</td>
                </tr>
                <tr>
                    <td>B14</td>
                    <td>-0.56</td>
                    <td>2</td>
                    <td>Sträng*</td>
                </tr>
                <tr>
                    <td>B11</td>
                    <td>-0.39</td>
                    <td>4</td>
                    <td>Något sträng</td>
                </tr>
                <tr>
                    <td>B12</td>
                    <td>-0.29</td>
                    <td>5</td>
                    <td>Något sträng</td>
                </tr>
                <tr>
                    <td>B08</td>
                    <td>-0.16</td>
                    <td>5</td>
                    <td>Något sträng</td>
                </tr>
                <tr>
                    <td>B07</td>
                    <td>-0.08</td>
                    <td>5</td>
                    <td>Neutral</td>
                </tr>
                <tr>
                    <td>B10</td>
                    <td>-0.04</td>
                    <td>4</td>
                    <td>Neutral</td>
                </tr>
                <tr>
                    <td>B09</td>
                    <td>0.05</td>
                    <td>4</td>
                    <td>Neutral</td>
                </tr>
                <tr>
                    <td>B02</td>
                    <td>0.27</td>
                    <td>5</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B03</td>
                    <td>0.30</td>
                    <td>5</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B06</td>
                    <td>0.31</td>
                    <td>3</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B01</td>
                    <td>0.40</td>
                    <td>6</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B05</td>
                    <td>0.49</td>
                    <td>3</td>
                    <td>Något generös</td>
                </tr>
                <tr>
                    <td>B04</td>
                    <td>0.56</td>
                    <td>3</td>
                    <td>Generös</td>
                </tr></tbody>
        </table>
        <p><em>*B14 har endast bedömt 2 uppsatser vilket gör värdet mycket osäkert</em></p>

        <h2>Avstånden mellan betygsstegen</h2>

        <p>Modellen visar att betygsstegen inte är jämnstora. Vissa övergångar kräver stora kvalitetshopp medan andra är små – en observation som stämmer väl med många lärares erfarenhet - och med grundtanken bakom betygsskalor, som antar att betyg är normalfördelade.</p>

        <div class="figure">
            <img src="figur3_betygströsklar.png" alt="Betygströsklar">
            <div class="figure-caption">
                <strong>Figur 3: Hur stora är stegen mellan betygen?</strong> Övre panelen visar betygsgränserna som färgzoner. Varje färg representerar ett betygsområde från F (mörkröd) till A (mörkgrön). Nedre panelen visar storleken på stegen mellan betygsnivåerna. Gröna staplar = små steg, orange = medelstora, röda = stora steg. De största hoppen är från D+ till C- och från C- till C+. För att ta sig över C-gränsen måste eleverna kraftigt förbättra sin skrivförmåga – något som stämmer väl med många lärares erfarenhet att just denna gräns är särskilt svår att passera.
            </div>
        </div>

        <div class="highlight">
            <h3>Praktisk betydelse</h3>
            <p>Analysen av faktiska avstånd mellan betygsnivåer visar att:</p>
            <ul>
                <li>Steget från D+ till C- är det minsta: 0.96 enheter</li>
                <li>Steget från C- till C+ är betydande: 1.26 enheter</li>
                <li>Steget från C+ till B är medelstort: 1.10 enheter</li>
            </ul>
            <p>OBS: Endast en uppsats fick E+ (JP24) samtidigt som ingen uppsats fick betyget D-, vilket gör det svårt att dra säkra slutsatser om dessa betygssteg.</p>
        </div>

        <h2>Bedömarsamstämmighet</h2>

        <p>Analyses av hur väl ni överensstämmer i era bedömningar.</p>

        <div class="figure">
            <img src="figur4_bedömarspridning.png" alt="Bedömarspridning">
            <div class="figure-caption">
                <strong>Figur 4: Bedömarspridning per uppsats.</strong> Vänstra panelen visar spridningen i bedömningar för varje uppsats, sorterad från högst till lägst. Gröna staplar = god samstämmighet (≤2 betygssteg), orange = måttlig oenighet (3 steg), röda = stor oenighet (≥4 steg). JP24 sticker ut med 5 betygssteg i spridning – här är bedömarna verkligen oense. LW24 har också stor spridning med 4 steg. Högra panelen visar fördelningen över alla uppsatser. Cirka 50% har god samstämmighet medan 33% har måttlig oenighet. Detta är faktiskt helt normalt för uppsatsbedömning – internationell forskning visar liknande mönster.
            </div>
        </div>

        <h3>Sammanfattande mått</h3>
        <ul>
            <li><strong>Krippendorffs alpha:</strong> 0.56 (måttlig samstämmighet)</li>
            <li><strong>Medianspridning:</strong> 2 betygssteg</li>
            <li><strong>Uppsatser med stor oenighet (≥3 steg):</strong> 50%</li>
            <li><strong>Uppsatser med mycket stor oenighet (≥4 steg):</strong> 16%</li>
        </ul>

        <p>Ett alpha-värde på 0.56 ligger under den gräns (0.667) som Krippendorff rekommenderar för att dra säkra slutsatser. Det är dock viktigt att komma ihåg att vi inte genomfört någon gemensam kalibreringsträning innan bedömningen – ni fick uppsatserna och bedömde dem individuellt utifrån era egna tolkningar av betygskriterierna. Med tanke på detta är 0.56 faktiskt inte så illa. Efter kalibreringsträffar brukar samstämmigheten öka markant.</p>

        <h2>Några problem och hur vi bäst löser dem</h2>

        <div class="warning">
            <h3>Problem: Ojämn bedömarmatris</h3>
            <p><strong>Flera bedömare har för få uppsatser:</strong></p>
            <ul>
                <li>B14: endast 2 uppsatser (behöver minst 3-4 till)</li>
                <li>B04, B05, B06: endast 3 uppsatser (behöver 2-3 till)</li>
                <li>B09, B10, B11: endast 4 uppsatser (behöver 1 till)</li>
            </ul>
            <p>Med fem bedömningar per person får vi tillförlitliga bedömarprofiler – både för varje individ och för gruppen som helhet. Detta ger oss underlag för framtida kalibrerande sambedömningsträffar.</p>
        </div>

        <h2>Mitt förslag på kompletterande bedömningar</h2>

        <div class="recommendation">
            <h3>Vem bedömer vad</h3>

            <h4>Första omgången:</h4>
            <ul>
                <li><strong>B14:</strong> <strong>EK24</strong> och <strong>ER24</strong></li>
            </ul>
            <p><em>Båda ligger på bara fyra bedömningar.</em></p>

            <h4>Andra omgången:</h4>
            <ul>
                <li><strong>B04:</strong> <strong>JP24</strong></li>
                <li><strong>B05:</strong> <strong>SA24</strong></li>
                <li><strong>B06:</strong> <strong>JA24</strong></li>
            </ul>
            <p><em>Då har alla bedömare minst fyra uppsatser. JP24 och SA24 får sin femte bedömning.</em></p>

            <h4>Tredje omgången – om vi vill ha fem uppsatser per person:</h4>
            <ul>
                <li><strong>B14:</strong> <strong>SN24</strong> eller <strong>TK24</strong></li>
                <li><strong>B04:</strong> <strong>II24</strong></li>
                <li><strong>B05:</strong> <strong>ES24</strong></li>
                <li><strong>B06:</strong> <strong>LW24</strong></li>
            </ul>

            <p>Med fem uppsatser per bedömare får modellen tillräckligt underlag för att skilja mellan verklig bedömarstränghet och slumpmässig variation. Då vet vi om någon verkligen är strängare eller om det bara såg ut så på grund av vilka uppsatser hen råkade få.</p>
        </div>

        <h2>Tidslinje</h2>

        <ol>
            <li><strong>Vecka 39-47:</strong> Kompletterande bedömningar enligt ovan</li>
            <li><strong>Vecka 48:</strong> Omkörning av analysen med fullständiga data</li>
            <li><strong>December/januari:</strong> Pilottest med elevernas mid-terms</li>
            <li><strong>Januari/februari:</strong> Eventuell finjustering baserat på pilottestets resultat</li>
            <li><strong>April/maj:</strong> Om allt fungerar kör vi om processen på riktigt i skarpt läge direkt efter NP, Del C: Writing (Eng 5 och om vi orkar: Eng 6)</li>
        </ol>

        <h2>Avslutande kommentarer</h2>

        <p>Analysen visar att ni bedömer olika – vissa är konsekvent strängare (negativa värden) medan andra är mer generösa (positiva värden) i sin bedömning. För vissa uppsatser skiljer det upp till fem betygssteg mellan er. Det är inget konstigt utan helt normalt! Poängen med den bayesianska modellen är att den kan räkna ut ett konsensusbetyg för varje uppsats, justerat för era individuella bedömarprofiler. De uppsatser som får stabila konsensusbetyg (hög konfidens) blir våra ankaruppsatser.</p>

        <p>Nästa steg blir att samla in de kompletterande bedömningarna enligt schemat ovan. Därefter kör vi om analysen och får förhoppningsvis mer tillförlitliga siffror för alla bedömare. I pilottestet får vi se om ankaruppsatserna verkligen fungerar som stabila referenspunkter när AI-systemet ska rangordna och betygsätta elevuppsatserna.</p>

        <p style="margin-top: 40px;"><em>Tack och hej, leverpastej,</em></p>
        <p><em>Olof</em></p>

        <hr style="margin-top: 50px; border: none; border-top: 1px solid #e0e0e0;">
        <p style="font-size: 0.9em; color: #666; margin-top: 20px;">
            <em>En oerhört parentetisk fotnot: Analysen baseras på en ordinal kumulativ logit-modell som skattar underliggande uppsatskvalitet (θ), bedömarstränghet (ρ) och betygsgränser (τ) samtidigt. Modellen använder nollsummerestriktion (Σρ = 0) för identifiering och monotont ökande betygsgränser. Inget antagande om lika avstånd mellan betygsstegen görs – stegen tillåts vara olika stora, vilket data bekräftar (särskilt de stora hoppen vid C-gränserna). Genomförd i Python/PyMC med 2000 MCMC-dragningar över 4 kedjor.</em>
        </p>
    </div>
</body>
</html>
